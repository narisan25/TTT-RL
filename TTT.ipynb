{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup TTT Board\n",
    "It might be more simplified.\n",
    "If you want computing efficiency, you can consider rotating/mirroring the board but I just don't do it cause this program is to understand only the Reinforcement Learning logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# POS State\n",
    "EMPTY=0\n",
    "PLAYER_X=1\n",
    "PLAYER_O=-1\n",
    "MARKS={PLAYER_X:\"X\",PLAYER_O:\"O\",EMPTY:\" \"}\n",
    "DRAW=2\n",
    "\n",
    "class TTTBoard:\n",
    "    \n",
    "    def __init__(self,board=None):\n",
    "        if board==None:\n",
    "            self.board = []\n",
    "            for i in range(9):self.board.append(EMPTY)\n",
    "        else:\n",
    "            self.board=board\n",
    "        self.winner=None\n",
    "    \n",
    "    def get_possible_pos(self):\n",
    "        pos=[]\n",
    "        for i in range(9):\n",
    "            if self.board[i]==EMPTY:\n",
    "                pos.append(i)\n",
    "        return pos\n",
    "    \n",
    "    def print_board(self):\n",
    "        tempboard=[]\n",
    "        for i in self.board:\n",
    "            tempboard.append(MARKS[i])\n",
    "        row = ' {} | {} | {} '\n",
    "        hr = '\\n-----------\\n'\n",
    "        print((row + hr + row + hr + row).format(*tempboard))\n",
    "               \n",
    "\n",
    "                    \n",
    "    def check_winner(self):\n",
    "        win_cond = ((1,2,3),(4,5,6),(7,8,9),(1,4,7),(2,5,8),(3,6,9),(1,5,9),(3,5,7))\n",
    "        for each in win_cond:\n",
    "            if self.board[each[0]-1] == self.board[each[1]-1]  == self.board[each[2]-1]:\n",
    "                if self.board[each[0]-1]!=EMPTY:\n",
    "                    self.winner=self.board[each[0]-1]\n",
    "                    return self.winner\n",
    "        return None\n",
    "    \n",
    "    def check_draw(self):\n",
    "        if len(self.get_possible_pos())==0 and self.winner is None:\n",
    "            self.winner=DRAW\n",
    "            return DRAW\n",
    "        return None\n",
    "    \n",
    "    def move(self,pos,player):\n",
    "        if self.board[pos]== EMPTY:\n",
    "            self.board[pos]=player\n",
    "        else:\n",
    "            self.winner=-1*player\n",
    "        self.check_winner()\n",
    "        self.check_draw()\n",
    "    \n",
    "    def clone(self):\n",
    "        return TTTBoard(self.board.copy())\n",
    "    \n",
    "    def switch_player(self):\n",
    "        if self.player_turn == self.player_x:\n",
    "            self.player_turn=self.player_o\n",
    "        else:\n",
    "            self.player_turn=self.player_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Game Organizer (it is like judge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class TTT_GameOrganizer:\n",
    "\n",
    "    act_turn=0\n",
    "    winner=None\n",
    "    \n",
    "    def __init__(self,px,po,nplay=1,showBoard=True,showResult=True,stat=100):\n",
    "        self.player_x=px\n",
    "        self.player_o=po\n",
    "        self.nwon={px.myturn:0,po.myturn:0,DRAW:0}\n",
    "        self.nplay=nplay\n",
    "        self.players=(self.player_x,self.player_o)\n",
    "        self.board=None\n",
    "        self.disp=showBoard\n",
    "        self.showResult=showResult\n",
    "        self.player_turn=self.players[random.randrange(2)]\n",
    "        self.nplayed=0\n",
    "        self.stat=stat\n",
    "    \n",
    "    def progress(self):\n",
    "        while self.nplayed<self.nplay:\n",
    "            self.board=TTTBoard()\n",
    "            while self.board.winner==None:\n",
    "                if self.disp:print(\"Turn is \"+self.player_turn.name)\n",
    "                act=self.player_turn.act(self.board)\n",
    "                self.board.move(act,self.player_turn.myturn)\n",
    "                if self.disp:self.board.print_board()\n",
    "               \n",
    "                if self.board.winner != None:\n",
    "                    # notice every player that game ends\n",
    "                    for i in self.players:\n",
    "                        i.getGameResult(self.board) \n",
    "                    if self.board.winner == DRAW:\n",
    "                        if self.showResult:print (\"Draw Game\")\n",
    "                    elif self.board.winner == self.player_turn.myturn:\n",
    "                        out = \"Winner : \" + self.player_turn.name\n",
    "                        if self.showResult: print(out)\n",
    "                    else:\n",
    "                        print (\"Invalid Move!\")\n",
    "                    self.nwon[self.board.winner]+=1\n",
    "                else:\n",
    "                    self.switch_player()\n",
    "                    #Notice other player that the game is going\n",
    "                    self.player_turn.getGameResult(self.board)\n",
    "\n",
    "            self.nplayed+=1\n",
    "            if self.nplayed%self.stat==0 or self.nplayed==self.nplay:\n",
    "                print(self.player_x.name+\":\"+str(self.nwon[self.player_x.myturn])+\",\"+self.player_o.name+\":\"+str(self.nwon[self.player_o.myturn])\n",
    "             +\",DRAW:\"+str(self.nwon[DRAW]))\n",
    "\n",
    "            \n",
    "    def switch_player(self):\n",
    "        if self.player_turn == self.player_x:\n",
    "            self.player_turn=self.player_o\n",
    "        else:\n",
    "            self.player_turn=self.player_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random player and Human Player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "             \n",
    "\n",
    "class PlayerRandom:\n",
    "    def __init__(self,turn):\n",
    "        self.name=\"Random\"\n",
    "        self.myturn=turn\n",
    "        \n",
    "    def act(self,board):\n",
    "        acts=board.get_possible_pos()\n",
    "        i=random.randrange(len(acts))\n",
    "        return acts[i]\n",
    "    \n",
    "    \n",
    "    def getGameResult(self,board):\n",
    "        pass\n",
    "\n",
    "    \n",
    "class PlayerHuman:\n",
    "    def __init__(self,turn):\n",
    "        self.name=\"Human\"\n",
    "        self.myturn=turn\n",
    "        \n",
    "    def act(self,board):\n",
    "        valid = False\n",
    "        while not valid:\n",
    "            try:\n",
    "                act = input(\"Where would you like to place \" + str(self.myturn) + \" (1-9)? \")\n",
    "                act = int(act)\n",
    "                #if act >= 1 and act <= 9 and board.board[act-1]==EMPTY:\n",
    "                if act >= 1 and act <= 9:\n",
    "                    valid=True\n",
    "                    return act-1\n",
    "                else:\n",
    "                    print (\"That is not a valid move! Please try again.\")\n",
    "            except Exception as e:\n",
    "                    print (act +  \"is not a valid move! Please try again.\")\n",
    "        return act\n",
    "    \n",
    "    def getGameResult(self,board):\n",
    "        if board.winner is not None and board.winner!=self.myturn and board.winner!=DRAW:\n",
    "            print(\"I lost...\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Turn is Random\n",
      "   |   |   \n",
      "-----------\n",
      "   |   | O \n",
      "-----------\n",
      "   |   |   \n",
      "Turn is Human\n",
      "Where would you like to place 1 (1-9)? 1\n",
      " X |   |   \n",
      "-----------\n",
      "   |   | O \n",
      "-----------\n",
      "   |   |   \n",
      "Turn is Random\n",
      " X |   |   \n",
      "-----------\n",
      " O |   | O \n",
      "-----------\n",
      "   |   |   \n",
      "Turn is Human\n",
      "Where would you like to place 1 (1-9)? 2\n",
      " X | X |   \n",
      "-----------\n",
      " O |   | O \n",
      "-----------\n",
      "   |   |   \n",
      "Turn is Random\n",
      " X | X |   \n",
      "-----------\n",
      " O | O | O \n",
      "-----------\n",
      "   |   |   \n",
      "I lost...\n",
      "Winner : Random\n",
      "Human:0,Random:1,DRAW:0\n"
     ]
    }
   ],
   "source": [
    "def Human_vs_Random():\n",
    "    \n",
    "    p1=PlayerHuman(PLAYER_X)\n",
    "    p2=PlayerRandom(PLAYER_O)\n",
    "    game=TTT_GameOrganizer(p1,p2)\n",
    "    game.progress()\n",
    "\n",
    "Human_vs_Random()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improved Random Player\n",
    "Alpha Random to check winnable next hand if exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class PlayerAlphaRandom:\n",
    "    \n",
    "    \n",
    "    def __init__(self,turn,name=\"AlphaRandom\"):\n",
    "        self.name=name\n",
    "        self.myturn=turn\n",
    "        \n",
    "    def getGameResult(self,winner):\n",
    "        pass\n",
    "        \n",
    "    def act(self,board):\n",
    "        acts=board.get_possible_pos()\n",
    "        #see only next winnable act\n",
    "        for act in acts:\n",
    "            tempboard=board.clone()\n",
    "            tempboard.move(act,self.myturn)\n",
    "            # check if win\n",
    "            if tempboard.winner==self.myturn:\n",
    "                #print (\"Check mate\")\n",
    "                return act\n",
    "        i=random.randrange(len(acts))\n",
    "        return acts[i]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Montecarlo Player\n",
    "Randomly (with checking winnable hand.) play till game end for N times of each next hand, then decide the most probably winnable hand.\n",
    "If N is more than 100, it is almost not defeatable.\n",
    "You can improve it to MCST Player, but TTT doesn't need such computing efficiency..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class PlayerMC:\n",
    "    def __init__(self,turn,name=\"MC\"):\n",
    "        self.name=name\n",
    "        self.myturn=turn\n",
    "    \n",
    "    def getGameResult(self,winner):\n",
    "        pass\n",
    "        \n",
    "    def win_or_rand(self,board,turn):\n",
    "        acts=board.get_possible_pos()\n",
    "        #see only next winnable act\n",
    "        for act in acts:\n",
    "            tempboard=board.clone()\n",
    "            tempboard.move(act,turn)\n",
    "            # check if win\n",
    "            if tempboard.winner==turn:\n",
    "                return act\n",
    "        i=random.randrange(len(acts))\n",
    "        return acts[i]\n",
    "           \n",
    "    def trial(self,score,board,act):\n",
    "        tempboard=board.clone()\n",
    "        tempboard.move(act,self.myturn)\n",
    "        tempturn=self.myturn\n",
    "        while tempboard.winner is None:\n",
    "            tempturn=tempturn*-1\n",
    "            tempboard.move(self.win_or_rand(tempboard,tempturn),tempturn)\n",
    "        \n",
    "        if tempboard.winner==self.myturn:\n",
    "            score[act]+=1\n",
    "        elif tempboard.winner==DRAW:\n",
    "            pass\n",
    "        else:\n",
    "            score[act]-=1\n",
    "\n",
    "        \n",
    "    def getGameResult(self,board):\n",
    "        pass\n",
    "        \n",
    "    \n",
    "    def act(self,board):\n",
    "        acts=board.get_possible_pos()\n",
    "        scores={}\n",
    "        n=50\n",
    "        for act in acts:\n",
    "            scores[act]=0\n",
    "            for i in range(n):\n",
    "                #print(\"Try\"+str(i))\n",
    "                self.trial(scores,board,act)\n",
    "            \n",
    "            #print(scores)\n",
    "            scores[act]/=n\n",
    "        \n",
    "        max_score=max(scores.values())\n",
    "        for act, v in scores.items():\n",
    "            if v == max_score:\n",
    "                #print(str(act)+\"=\"+str(v))\n",
    "                return act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Draw Game\n",
      "Winner : M2\n",
      "Draw Game\n",
      "Draw Game\n",
      "Draw Game\n",
      "Draw Game\n",
      "Draw Game\n",
      "Winner : M2\n",
      "Draw Game\n",
      "Draw Game\n",
      "M1:0,M2:2,DRAW:8\n"
     ]
    }
   ],
   "source": [
    "#p1=PlayerAlphaRandom(PLAYER_X)\n",
    "p1=PlayerMC(PLAYER_X,\"M1\")\n",
    "p2=PlayerMC(PLAYER_O,\"M2\")\n",
    "#p2=PlayerHuman(PLAYER_O)\n",
    "game=TTT_GameOrganizer(p1,p2,10,False)\n",
    "game.progress()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q-Learning Player (Look up Q(s,a) table)\n",
    "\n",
    "Q(s,a) = Q(s,a) + alpha (reward + gammma* max(Q(s',a')- Q(s,a))\n",
    "The struggled points are ...\n",
    "- epliron to be shurinked to zero considering try counts\n",
    "- need to learn Q every step, not only at the game end\n",
    "- if at the game end (=terminal state) like DRAW,WIN, maxQ is zero\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "class PlayerQL:\n",
    "    def __init__(self,turn,name=\"QL\",e=0.2,alpha=0.3):\n",
    "        self.name=name\n",
    "        self.myturn=turn\n",
    "        self.q={} #set of s,a\n",
    "        self.e=e\n",
    "        self.alpha=alpha\n",
    "        self.gamma=0.9\n",
    "        self.last_move=None\n",
    "        self.last_board=None\n",
    "        self.totalgamecount=0\n",
    "        \n",
    "    \n",
    "    def policy(self,board):\n",
    "        self.last_board=board.clone()\n",
    "        acts=board.get_possible_pos()\n",
    "        #Explore sometimes\n",
    "        if random.random() < (self.e/(self.totalgamecount//10000+1)):\n",
    "                i=random.randrange(len(acts))\n",
    "                return acts[i]\n",
    "        qs = [self.getQ(tuple(self.last_board.board),act) for act in acts]\n",
    "        maxQ= max(qs)\n",
    "\n",
    "        if qs.count(maxQ) > 1:\n",
    "            # more than 1 best option; choose among them randomly\n",
    "            best_options = [i for i in range(len(acts)) if qs[i] == maxQ]\n",
    "            i = random.choice(best_options)\n",
    "        else:\n",
    "            i = qs.index(maxQ)\n",
    "\n",
    "        self.last_move = acts[i]\n",
    "        return acts[i]\n",
    "    \n",
    "    def getQ(self, state, act):\n",
    "        # encourage exploration; \"optimistic\" 1.0 initial values\n",
    "        if self.q.get((state, act)) is None:\n",
    "            self.q[(state, act)] = 1\n",
    "        return self.q.get((state, act))\n",
    "    \n",
    "    def getGameResult(self,board):\n",
    "        r=0\n",
    "        if self.last_move is not None:\n",
    "            if board.winner is None:\n",
    "                self.learn(self.last_board,self.last_move, 0, board)\n",
    "                pass\n",
    "            else:\n",
    "                if board.winner == self.myturn:\n",
    "                    self.learn(self.last_board,self.last_move, 1, board)\n",
    "                elif board.winner !=DRAW:\n",
    "                    self.learn(self.last_board,self.last_move, -1, board)\n",
    "                else:\n",
    "                    self.learn(self.last_board,self.last_move, 0, board)\n",
    "                self.totalgamecount+=1\n",
    "                self.last_move=None\n",
    "                self.last_board=None\n",
    "\n",
    "    def learn(self,s,a,r,fs):\n",
    "        pQ=self.getQ(tuple(s.board),a)\n",
    "        if fs.winner is not None:\n",
    "            maxQnew=0\n",
    "        else:\n",
    "            maxQnew=max([self.getQ(tuple(fs.board),act) for act in fs.get_possible_pos()])\n",
    "        self.q[(tuple(s.board),a)]=pQ+self.alpha*((r+self.gamma*maxQnew)-pQ)\n",
    "        #print (str(s.board)+\"with \"+str(a)+\" is updated from \"+str(pQ)+\" refs MAXQ=\"+str(maxQnew)+\":\"+str(r))\n",
    "        #print(self.q)\n",
    "\n",
    "    \n",
    "    def act(self,board):\n",
    "        return self.policy(board)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Q by themselves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QL1:4371,QL2:4436,DRAW:1193\n",
      "QL1:8328,QL2:8456,DRAW:3216\n",
      "QL1:11903,QL2:11952,DRAW:6145\n",
      "QL1:14268,QL2:14221,DRAW:11511\n",
      "QL1:15221,QL2:15099,DRAW:19680\n",
      "QL1:15730,QL2:15667,DRAW:28603\n",
      "QL1:16136,QL2:16090,DRAW:37774\n",
      "QL1:16489,QL2:16439,DRAW:47072\n",
      "QL1:16832,QL2:16791,DRAW:56377\n",
      "QL1:17128,QL2:17121,DRAW:65751\n"
     ]
    }
   ],
   "source": [
    "pQ=PlayerQL(PLAYER_O,\"QL1\")\n",
    "p2=PlayerQL(PLAYER_X,\"QL2\")\n",
    "game=TTT_GameOrganizer(pQ,p2,100000,False,False,10000)\n",
    "game.progress()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QL1:1,M1:0,DRAW:9\n",
      "QL1:1,M1:0,DRAW:19\n",
      "QL1:2,M1:0,DRAW:28\n",
      "QL1:2,M1:0,DRAW:38\n",
      "QL1:3,M1:0,DRAW:47\n",
      "QL1:4,M1:0,DRAW:56\n",
      "QL1:5,M1:0,DRAW:65\n",
      "QL1:5,M1:0,DRAW:75\n",
      "QL1:6,M1:0,DRAW:84\n",
      "QL1:6,M1:0,DRAW:94\n"
     ]
    }
   ],
   "source": [
    "pQ.e=0\n",
    "p2=PlayerMC(PLAYER_X,\"M1\")\n",
    "game=TTT_GameOrganizer(pQ,p2,100,False,False,10)\n",
    "game.progress()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now time to play with Computer\n",
    "Human misses but computer never... It's wasting time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p1.e=0\n",
    "p2=PlayerHuman(PLAYER_O)\n",
    "game=TTT_GameOrganizer(p1,p2,3)\n",
    "#game.progress()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Q network Player\n",
    "Q-Learning is to store Q(s,a) table but it is memory consuming... and can't use for large space problems..\n",
    "So Deep Q Network is Q(s) to output best Action. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import chainer\n",
    "\n",
    "from chainer import Function, gradient_check, Variable, optimizers, serializers, utils\n",
    "import chainer.functions as F\n",
    "import chainer.links as L\n",
    "import numpy as np\n",
    "from chainer import computational_graph as c\n",
    "\n",
    "# Network definition\n",
    "class MLP(chainer.Chain):\n",
    "\n",
    "    def __init__(self, n_in, n_units, n_out):\n",
    "        super(MLP, self).__init__(\n",
    "            l1=L.Linear(n_in, n_units),  # first layer\n",
    "            l2=L.Linear(n_units, n_units),  # second layer\n",
    "            l3=L.Linear(n_units, n_units),  # Third layer\n",
    "            l4=L.Linear(n_units, n_out),  # output layer\n",
    "        )\n",
    "\n",
    "    def __call__(self, x, t=None, train=False):\n",
    "        h = F.leaky_relu(self.l1(x))\n",
    "        h = F.leaky_relu(self.l2(h))\n",
    "        h = F.leaky_relu(self.l3(h))\n",
    "        h = self.l4(h)\n",
    "\n",
    "        if train:\n",
    "            return F.mean_squared_error(h,t)\n",
    "        else:\n",
    "            return h\n",
    "\n",
    "    def get(self,x):\n",
    "        # input x as float, output float\n",
    "        return self.predict(Variable(np.array([x]).astype(np.float32).reshape(1,1))).data[0][0]\n",
    "\n",
    "\n",
    "class DQNPlayer:\n",
    "    def __init__(self, turn,name=\"DQN\",e=1,dispPred=False):\n",
    "        self.name=name\n",
    "        self.myturn=turn\n",
    "        self.model = MLP(9, 162,9)\n",
    "        self.optimizer = optimizers.SGD()\n",
    "        self.optimizer.setup(self.model)\n",
    "        self.e=e\n",
    "        self.gamma=0.95\n",
    "        self.dispPred=dispPred\n",
    "        self.last_move=None\n",
    "        self.last_board=None\n",
    "        self.last_pred=None\n",
    "        self.totalgamecount=0\n",
    "        self.rwin,self.rlose,self.rdraw,self.rmiss=1,-1,0,-1.5\n",
    "        \n",
    "    \n",
    "    def act(self,board):\n",
    "        \n",
    "        self.last_board=board.clone()\n",
    "        x=np.array([board.board],dtype=np.float32).astype(np.float32)\n",
    "        \n",
    "        pred=self.model(x)\n",
    "        if self.dispPred:print(pred.data)\n",
    "        self.last_pred=pred.data[0,:]\n",
    "        act=np.argmax(pred.data,axis=1)\n",
    "        if self.e > 0.2: #decrement epsilon over time\n",
    "            self.e -= 1/(20000)\n",
    "        if random.random() < self.e:\n",
    "            acts=board.get_possible_pos()\n",
    "            i=random.randrange(len(acts))\n",
    "            act=acts[i]\n",
    "        i=0\n",
    "        while board.board[act]!=EMPTY:\n",
    "            #print(\"Wrong Act \"+str(board.board)+\" with \"+str(act))\n",
    "            self.learn(self.last_board,act, -1, self.last_board)\n",
    "            x=np.array([board.board],dtype=np.float32).astype(np.float32)\n",
    "            pred=self.model(x)\n",
    "            #print(pred.data)\n",
    "            act=np.argmax(pred.data,axis=1)\n",
    "            i+=1\n",
    "            if i>10:\n",
    "                print(\"Exceed Pos Find\"+str(board.board)+\" with \"+str(act))\n",
    "                acts=self.last_board.get_possible_pos()\n",
    "                act=acts[random.randrange(len(acts))]\n",
    "            \n",
    "        self.last_move=act\n",
    "        #self.last_pred=pred.data[0,:]\n",
    "        return act\n",
    "    \n",
    "    def getGameResult(self,board):\n",
    "        r=0\n",
    "        if self.last_move is not None:\n",
    "            if board.winner is None:\n",
    "                self.learn(self.last_board,self.last_move, 0, board)\n",
    "                pass\n",
    "            else:\n",
    "                if board.board== self.last_board.board:            \n",
    "                    self.learn(self.last_board,self.last_move, self.rmiss, board)\n",
    "                elif board.winner == self.myturn:\n",
    "                    self.learn(self.last_board,self.last_move, self.rwin, board)\n",
    "                elif board.winner !=DRAW:\n",
    "                    self.learn(self.last_board,self.last_move, self.rlose, board)\n",
    "                else:                    #DRAW\n",
    "                    self.learn(self.last_board,self.last_move, self.rdraw, board)\n",
    "                self.totalgamecount+=1\n",
    "                self.last_move=None\n",
    "                self.last_board=None\n",
    "                self.last_pred=None\n",
    "\n",
    "    def learn(self,s,a,r,fs):\n",
    "        if fs.winner is not None:\n",
    "            maxQnew=0\n",
    "        else:\n",
    "            x=np.array([fs.board],dtype=np.float32).astype(np.float32)\n",
    "            maxQnew=np.max(self.model(x).data[0])\n",
    "        update=r+self.gamma*maxQnew\n",
    "        #print(('Prev Board:{} ,ACT:{}, Next Board:{}, Get Reward {}, Update {}').format(s.board,a,fs.board,r,update))\n",
    "        #print(('PREV:{}').format(self.last_pred))\n",
    "        self.last_pred[a]=update\n",
    "        \n",
    "        x=np.array([s.board],dtype=np.float32).astype(np.float32)\n",
    "        t=np.array([self.last_pred],dtype=np.float32).astype(np.float32)\n",
    "        self.model.zerograds()\n",
    "        loss=self.model(x,t,train=True)\n",
    "        loss.backward()\n",
    "        self.optimizer.update()\n",
    "        #print(('Updated:{}').format(self.model(x).data))\n",
    "        #print (str(s.board)+\"with \"+str(a)+\" is updated from \"+str(pQ)+\" refs MAXQ=\"+str(maxQnew)+\":\"+str(r))\n",
    "        #print(self.q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DQN vs AlphaRandom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:69: VisibleDeprecationWarning: converting an array with ndim > 0 to an index will result in an error in the future\n",
      "//anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:51: VisibleDeprecationWarning: converting an array with ndim > 0 to an index will result in an error in the future\n",
      "//anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:52: VisibleDeprecationWarning: converting an array with ndim > 0 to an index will result in an error in the future\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DQN:206,AlphaRandom:727,DRAW:67\n",
      "DQN:468,AlphaRandom:1406,DRAW:126\n",
      "DQN:861,AlphaRandom:1959,DRAW:180\n",
      "DQN:1458,AlphaRandom:2315,DRAW:227\n",
      "DQN:2185,AlphaRandom:2560,DRAW:255\n",
      "DQN:3022,AlphaRandom:2704,DRAW:274\n",
      "DQN:3832,AlphaRandom:2856,DRAW:312\n",
      "DQN:4632,AlphaRandom:3023,DRAW:345\n",
      "DQN:5481,AlphaRandom:3153,DRAW:366\n",
      "DQN:6326,AlphaRandom:3280,DRAW:394\n",
      "DQN:7181,AlphaRandom:3400,DRAW:419\n",
      "DQN:8032,AlphaRandom:3522,DRAW:446\n",
      "DQN:8902,AlphaRandom:3618,DRAW:480\n",
      "DQN:9791,AlphaRandom:3705,DRAW:504\n",
      "DQN:10673,AlphaRandom:3793,DRAW:534\n",
      "DQN:11545,AlphaRandom:3893,DRAW:562\n",
      "DQN:12420,AlphaRandom:3986,DRAW:594\n",
      "DQN:13300,AlphaRandom:4074,DRAW:626\n",
      "DQN:14183,AlphaRandom:4158,DRAW:659\n",
      "DQN:15058,AlphaRandom:4246,DRAW:696\n"
     ]
    }
   ],
   "source": [
    "pDQ=DQNPlayer(PLAYER_X)\n",
    "p2=PlayerAlphaRandom(PLAYER_O)\n",
    "game=TTT_GameOrganizer(pDQ,p2,20000,False,False,1000)\n",
    "game.progress()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DQN vs Q-Learning (Look up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:69: VisibleDeprecationWarning: converting an array with ndim > 0 to an index will result in an error in the future\n",
      "//anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:51: VisibleDeprecationWarning: converting an array with ndim > 0 to an index will result in an error in the future\n",
      "//anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:52: VisibleDeprecationWarning: converting an array with ndim > 0 to an index will result in an error in the future\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DQN:4,QL1:436,DRAW:560\n",
      "DQN:6,QL1:790,DRAW:1204\n",
      "DQN:6,QL1:1135,DRAW:1859\n",
      "DQN:6,QL1:1472,DRAW:2522\n",
      "DQN:6,QL1:1801,DRAW:3193\n",
      "DQN:6,QL1:2123,DRAW:3871\n",
      "DQN:6,QL1:2439,DRAW:4555\n",
      "DQN:6,QL1:2777,DRAW:5217\n",
      "DQN:7,QL1:3128,DRAW:5865\n",
      "DQN:9,QL1:3648,DRAW:6343\n",
      "DQN:13,QL1:4132,DRAW:6855\n",
      "DQN:13,QL1:4606,DRAW:7381\n",
      "DQN:13,QL1:5087,DRAW:7900\n",
      "DQN:14,QL1:5536,DRAW:8450\n",
      "DQN:14,QL1:6011,DRAW:8975\n",
      "DQN:14,QL1:6496,DRAW:9490\n",
      "DQN:14,QL1:7394,DRAW:9592\n",
      "DQN:14,QL1:7925,DRAW:10061\n",
      "DQN:16,QL1:8357,DRAW:10627\n",
      "DQN:16,QL1:8777,DRAW:11207\n"
     ]
    }
   ],
   "source": [
    "#pDQ=DQNPlayer(PLAYER_X)\n",
    "pDQ.e=1\n",
    "game=TTT_GameOrganizer(pDQ,pQ,30000,False,False,1000)\n",
    "game.progress()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DQN vs Human"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Turn is Human\n",
      "Where would you like to place -1 (1-9)? 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:69: VisibleDeprecationWarning: converting an array with ndim > 0 to an index will result in an error in the future\n",
      "//anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:51: VisibleDeprecationWarning: converting an array with ndim > 0 to an index will result in an error in the future\n",
      "//anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:52: VisibleDeprecationWarning: converting an array with ndim > 0 to an index will result in an error in the future\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " O |   |   \n",
      "-----------\n",
      "   |   |   \n",
      "-----------\n",
      "   |   |   \n",
      "Turn is DQN\n",
      " O |   |   \n",
      "-----------\n",
      "   | X |   \n",
      "-----------\n",
      "   |   |   \n",
      "Turn is Human\n",
      "Where would you like to place -1 (1-9)? 2\n",
      " O | O |   \n",
      "-----------\n",
      "   | X |   \n",
      "-----------\n",
      "   |   |   \n",
      "Turn is DQN\n",
      " O | O | X \n",
      "-----------\n",
      "   | X |   \n",
      "-----------\n",
      "   |   |   \n",
      "Turn is Human\n",
      "Where would you like to place -1 (1-9)? 7\n",
      " O | O | X \n",
      "-----------\n",
      "   | X |   \n",
      "-----------\n",
      " O |   |   \n",
      "Turn is DQN\n",
      " O | O | X \n",
      "-----------\n",
      " X | X |   \n",
      "-----------\n",
      " O |   |   \n",
      "Turn is Human\n",
      "Where would you like to place -1 (1-9)? 6\n",
      " O | O | X \n",
      "-----------\n",
      " X | X | O \n",
      "-----------\n",
      " O |   |   \n",
      "Turn is DQN\n",
      " O | O | X \n",
      "-----------\n",
      " X | X | O \n",
      "-----------\n",
      " O |   | X \n",
      "Turn is Human\n",
      "Where would you like to place -1 (1-9)? 7\n",
      " O | O | X \n",
      "-----------\n",
      " X | X | O \n",
      "-----------\n",
      " O |   | X \n",
      "I lost...\n",
      "Invalid Move!\n",
      "Turn is Human\n",
      "Where would you like to place -1 (1-9)? 2\n",
      "   | O |   \n",
      "-----------\n",
      "   |   |   \n",
      "-----------\n",
      "   |   |   \n",
      "Turn is DQN\n",
      "   | O |   \n",
      "-----------\n",
      "   | X |   \n",
      "-----------\n",
      "   |   |   \n",
      "Turn is Human\n",
      "Where would you like to place -1 (1-9)? 1\n",
      " O | O |   \n",
      "-----------\n",
      "   | X |   \n",
      "-----------\n",
      "   |   |   \n",
      "Turn is DQN\n",
      " O | O | X \n",
      "-----------\n",
      "   | X |   \n",
      "-----------\n",
      "   |   |   \n",
      "Turn is Human\n",
      "Where would you like to place -1 (1-9)? 7\n",
      " O | O | X \n",
      "-----------\n",
      "   | X |   \n",
      "-----------\n",
      " O |   |   \n",
      "Turn is DQN\n",
      " O | O | X \n",
      "-----------\n",
      " X | X |   \n",
      "-----------\n",
      " O |   |   \n",
      "Turn is Human\n",
      "Where would you like to place -1 (1-9)? 6\n",
      " O | O | X \n",
      "-----------\n",
      " X | X | O \n",
      "-----------\n",
      " O |   |   \n",
      "Turn is DQN\n",
      " O | O | X \n",
      "-----------\n",
      " X | X | O \n",
      "-----------\n",
      " O |   | X \n",
      "Turn is Human\n",
      "Where would you like to place -1 (1-9)? 8\n",
      " O | O | X \n",
      "-----------\n",
      " X | X | O \n",
      "-----------\n",
      " O | O | X \n",
      "Draw Game\n",
      "DQN:1,Human:0,DRAW:1\n"
     ]
    }
   ],
   "source": [
    "#pDQ=DQNPlayer(PLAYER_X,e=0.1)\n",
    "pDQ.e=0\n",
    "p2=PlayerHuman(PLAYER_O)\n",
    "game=TTT_GameOrganizer(pDQ,p2,2)\n",
    "game.progress()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
